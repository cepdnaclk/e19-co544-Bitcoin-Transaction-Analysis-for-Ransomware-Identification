{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORTuC6zGJV2AD2821nDmpn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cepdnaclk/e19-co544-Bitcoin-Transaction-Analysis-for-Ransomware-Identification/blob/main/deployments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWqHO_1o7zV2"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install mlflow\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import subprocess\n",
        "from pyngrok import ngrok, conf\n",
        "import getpass"
      ],
      "metadata": {
        "id": "DLYjIvMc8E0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\"\n",
        "subprocess.Popen([\"mlflow\", \"ui\", \"--backend-store-uri\", MLFLOW_TRACKING_URI])"
      ],
      "metadata": {
        "id": "3dbuhpCo8H-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55bd70a2-5d13-4ef5-fec3-a41e67d5ff3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: ['mlflow', 'ui', '--backend-store-uri', 'sqli...>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
        "# mlflow will create an experiment if it doesn't exist\n",
        "mlflow.set_experiment(\"duration-prediction-experiment\")"
      ],
      "metadata": {
        "id": "Q0z4Yzwn8LEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "640fd9db-3d9e-43c8-98bf-ca6476f33034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='/content/mlruns/1', creation_time=1719404768899, experiment_id='1', last_update_time=1719404768899, lifecycle_stage='active', name='duration-prediction-experiment', tags={}>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Enter your authtoken, which can be copied from https://dashboard.ngrok.com/auth\")\n",
        "conf.get_default().auth_token = getpass.getpass()\n",
        "port=5000\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(f' * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:{port}\\\"')"
      ],
      "metadata": {
        "id": "qngZvRw58ONR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4e3e3e0-dfa4-4902-a894-49a49514e866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your authtoken, which can be copied from https://dashboard.ngrok.com/auth\n",
            "··········\n",
            " * ngrok tunnel \"https://daf8-34-106-119-54.ngrok-free.app\" -> \"http://127.0.0.1:5000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from google.colab import drive\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import mlflow.xgboost\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "YkSkVaMf9aiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "84UMZFgvh1Lw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "4fbb2fbd-a355-4d87-8912-7d9519aeb252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5c70a6c657be>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         )\n\u001b[0;32m--> 283\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "test_set = pd.read_csv('/content/drive/MyDrive/dataset_project/bitcoin_test_dataset.csv')\n",
        "training_set = pd.read_csv('/content/drive/MyDrive/dataset_project/bitcoin_training_dataset.csv')\n",
        "\n",
        "# Prepare data\n",
        "X_train = training_set.drop(columns=['label'])\n",
        "X_test = test_set.drop(columns=['label'])\n",
        "y_train = training_set['label']\n",
        "y_test = test_set['label']\n"
      ],
      "metadata": {
        "id": "3DjnykoB9fMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model 1"
      ],
      "metadata": {
        "id": "Ula5qj118Qt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create polynomial features\n",
        "poly = PolynomialFeatures(degree=3)\n",
        "X_poly_train = poly.fit_transform(X_train)\n",
        "X_poly_test = poly.transform(X_test)\n",
        "\n",
        "# Set the experiment name (create if it doesn't exist)\n",
        "experiment_name = \"Bitcoin_Prediction_Experiment\"\n",
        "mlflow.set_experiment(experiment_name)\n",
        "\n",
        "# Start a new MLflow run with a descriptive run name\n",
        "with mlflow.start_run(run_name=\"Initial_Logistic_Regression_Training\"):\n",
        "    # Train the model\n",
        "    model = LogisticRegression(max_iter=4000)\n",
        "    model.fit(X_poly_train, y_train)\n",
        "    y_pred = model.predict(X_poly_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='macro')\n",
        "    recall = recall_score(y_test, y_pred, average='macro')\n",
        "    f1 = f1_score(y_test, y_pred, average='macro')\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    # Log the model\n",
        "    mlflow.sklearn.log_model(model, \"logistic_regression_model\")\n",
        "\n",
        "    # Register the model\n",
        "    model_uri = \"runs:/{}/logistic_regression_model\".format(mlflow.active_run().info.run_id)\n",
        "    mlflow.register_model(model_uri=model_uri, name=\"logistic_regression_model\")\n",
        "\n",
        "    # Log parameters and metrics\n",
        "    mlflow.log_param(\"solver\", \"lbfgs\")\n",
        "    mlflow.log_param(\"max_iter\", model.max_iter)\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"precision\", precision)\n",
        "    mlflow.log_metric(\"recall\", recall)\n",
        "    mlflow.log_metric(\"f1\", f1)\n",
        "\n",
        "    # Log classification report as an artifact\n",
        "    with open(\"classification_report.txt\", \"w\") as f:\n",
        "        f.write(report)\n",
        "    mlflow.log_artifact(\"classification_report.txt\")\n",
        "\n",
        "    print(f\"Initial Accuracy: {accuracy}\")\n",
        "    print(\"Initial Classification Report:\")\n",
        "    print(report)"
      ],
      "metadata": {
        "id": "xPTrELKt8QWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model 2"
      ],
      "metadata": {
        "id": "03IaQeHG8THC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Start a new MLflow run with a descriptive run name\n",
        "with mlflow.start_run(run_name=\"SVM_Training\"):\n",
        "    # Train the model\n",
        "    model = SVC()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Prediction\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Classification report\n",
        "    train_report = classification_report(y_train, y_train_pred)\n",
        "    test_report = classification_report(y_test, y_pred)\n",
        "\n",
        "    # Evaluate the model\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "    test_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(\"Training classification report:\\n\", train_report)\n",
        "    print(\"Test classification report:\\n\", test_report)\n",
        "\n",
        "    # Log the model\n",
        "    mlflow.sklearn.log_model(model, \"svm_model\")\n",
        "\n",
        "    # Register the model (optional)\n",
        "    model_uri = \"runs:/{}/svm_model\".format(mlflow.active_run().info.run_id)\n",
        "    mlflow.register_model(model_uri=model_uri, name=\"svm_model\")\n",
        "\n",
        "    # Log parameters and metrics\n",
        "    mlflow.log_param(\"kernel\", model.kernel)\n",
        "    mlflow.log_param(\"C\", model.C)\n",
        "    mlflow.log_param(\"degree\", model.degree)\n",
        "    mlflow.log_param(\"gamma\", model.gamma)\n",
        "\n",
        "\n",
        "    mlflow.log_metric('accuracy', accuracy)\n",
        "    mlflow.log_metric('precision', precision)\n",
        "    mlflow.log_metric('recall', recall)\n",
        "    mlflow.log_metric('f1', f1)\n",
        "\n",
        "    # Log classification reports as artifacts\n",
        "    with open(\"train_classification_report.txt\", \"w\") as f:\n",
        "        f.write(train_report)\n",
        "    mlflow.log_artifact(\"train_classification_report.txt\")\n",
        "\n",
        "    with open(\"test_classification_report.txt\", \"w\") as f:\n",
        "        f.write(test_report)\n",
        "    mlflow.log_artifact(\"test_classification_report.txt\")\n"
      ],
      "metadata": {
        "id": "NbZy9vLJ8SQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model 3"
      ],
      "metadata": {
        "id": "01a7H5Pb8Ubu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "best_params = {'bootstrap': True, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}\n",
        "\n",
        "# Start a new MLflow run with a descriptive run name\n",
        "with mlflow.start_run(run_name=\"Random_Forest_Training\"):\n",
        "    # Create a Random Forest Classifier\n",
        "    rf = RandomForestClassifier(**best_params)\n",
        "\n",
        "    # Fit the model\n",
        "    rf.fit(X_train, y_train)\n",
        "\n",
        "    # Predict the test set\n",
        "    y_pred = rf.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    print(\"Accuracy: \", accuracy)\n",
        "    print(\"Precision: \", precision)\n",
        "    print(\"Recall: \", recall)\n",
        "    print(\"F1: \", f1)\n",
        "\n",
        "    # Classification Report\n",
        "    class_report = classification_report(y_test, y_pred)\n",
        "    print(class_report)\n",
        "\n",
        "    # Log the model\n",
        "    mlflow.sklearn.log_model(rf, \"random_forest_model\")\n",
        "\n",
        "    # Register the model (optional)\n",
        "    model_uri = \"runs:/{}/random_forest_model\".format(mlflow.active_run().info.run_id)\n",
        "    mlflow.register_model(model_uri=model_uri, name=\"random_forest_model\")\n",
        "\n",
        "    # Log parameters\n",
        "    mlflow.log_params(best_params)\n",
        "\n",
        "    # Log metrics\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"precision\", precision)\n",
        "    mlflow.log_metric(\"recall\", recall)\n",
        "    mlflow.log_metric(\"f1\", f1)\n",
        "\n",
        "    # Log classification report as an artifact\n",
        "    with open(\"classification_report.txt\", \"w\") as f:\n",
        "        f.write(class_report)\n",
        "    mlflow.log_artifact(\"classification_report.txt\")"
      ],
      "metadata": {
        "id": "MOg4NQ-X8VmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model 4\n"
      ],
      "metadata": {
        "id": "ytADAGIA8WF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.xgboost\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "bitcoin_dataset_oversampled = pd.read_csv('/content/drive/MyDrive/BitcoinStandardScalerOversampled.csv')\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "target = 'label'\n",
        "X = bitcoin_dataset_oversampled.drop(columns=[target])\n",
        "y = bitcoin_dataset_oversampled[target]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "def evaluate_model(y_true, y_pred, model_name=\"Model\"):\n",
        "    precision = precision_score(y_true, y_pred, average='macro')\n",
        "    recall = recall_score(y_true, y_pred, average='macro')\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    # Log metrics\n",
        "    mlflow.log_metric('accuracy', accuracy)\n",
        "    mlflow.log_metric('precision', precision)\n",
        "    mlflow.log_metric('recall', recall)\n",
        "    mlflow.log_metric('f1', f1)\n",
        "\n",
        "    print(f\"--- {model_name} ---\")\n",
        "    print(f\"Accuracy: {accuracy:.3f}\")\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "    print(f\"Recall: {recall:.2f}\")\n",
        "    print(f\"F1 Score: {f1:.2f}\")\n",
        "    print(\"\\n\")\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "with mlflow.start_run(run_name=\"XGBoost_Training\"):\n",
        "    # Convert Data to DMatrix\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "    # Set Parameters\n",
        "    params = {\n",
        "        'booster': 'gbtree',\n",
        "        'objective': 'multi:softprob',\n",
        "        'num_class': 3,\n",
        "        'eta': 0.3,\n",
        "        'max_depth': 6,\n",
        "        'eval_metric': 'mlogloss'\n",
        "    }\n",
        "\n",
        "    # Train the Model\n",
        "    num_round = 100\n",
        "    bst = xgb.train(params, dtrain, num_round)\n",
        "\n",
        "    # Predict the test set\n",
        "    preds = bst.predict(dtest)\n",
        "    best_preds = [int(np.argmax(line)) for line in preds]\n",
        "\n",
        "    # Log the model\n",
        "    mlflow.xgboost.log_model(bst, 'model')\n",
        "\n",
        "    # Evaluate the model and log the evaluation\n",
        "    accuracy, precision, recall, f1 = evaluate_model(y_test, best_preds, \"XGBoost\")\n",
        "\n",
        "    # Log parameters\n",
        "    mlflow.log_params(params)\n",
        "\n",
        "    # Log classification report as an artifact\n",
        "    class_report = classification_report(y_test, best_preds)\n",
        "    with open(\"classification_report.txt\", \"w\") as f:\n",
        "        f.write(class_report)\n",
        "    mlflow.log_artifact(\"classification_report.txt\")\n",
        "\n",
        "    # Register the Model\n",
        "    model_name = 'xgboost_m1'\n",
        "    model_uri = 'runs:/{}/model'.format(mlflow.active_run().info.run_id)\n",
        "    mlflow.register_model(model_uri=model_uri, name=model_name)\n"
      ],
      "metadata": {
        "id": "KPGYcY8-8XE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "saCOD3mU8X7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow.pyfunc\n",
        "\n",
        "# Load the model using the registered model name and version\n",
        "model_name = \"logistic_regression_model\"\n",
        "model_version = 1  # Specify the version of the model you want to use\n",
        "model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{model_version}\")\n",
        "\n",
        "# Prepare a new data point for prediction (replace with actual data)\n",
        "new_data = pd.DataFrame({\n",
        "    \"length\": [1.080547],\n",
        "    \"weight\": [-1.245423],\n",
        "    \"neighbors\": [2.209168],\n",
        "    \"income\": [1.838642],\n",
        "    \"looped\": [1.763154],\n",
        "    \"count\": [0.223435]\n",
        "})\n",
        "\n",
        "poly = PolynomialFeatures(degree=3)  # You can change the degree as needed\n",
        "new_data_poly = poly.fit_transform(new_data)\n",
        "\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(new_data_poly)\n",
        "print(\"Predictions:\", predictions)\n"
      ],
      "metadata": {
        "id": "JUY-d0CQZmI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow.pyfunc\n",
        "\n",
        "# Load the model using the registered model name and version\n",
        "model_name = \"svm_model\"\n",
        "model_version = 1  # Specify the version of the model you want to use\n",
        "model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{model_version}\")\n",
        "\n",
        "# Prepare a new data point for prediction (replace with actual data)\n",
        "new_data = pd.DataFrame({\n",
        "    \"length\": [1.080547],\n",
        "    \"weight\": [-1.245423],\n",
        "    \"neighbors\": [2.209168],\n",
        "    \"income\": [1.838642],\n",
        "    \"looped\": [1.763154],\n",
        "    \"count\": [0.223435]\n",
        "})\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(new_data)\n",
        "print(\"Predictions:\", predictions)\n"
      ],
      "metadata": {
        "id": "Bztz2aZl8a46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow.pyfunc\n",
        "\n",
        "# Load the model using the registered model name and version\n",
        "model_name = \"random_forest_model\"\n",
        "model_version = 1  # Specify the version of the model you want to use\n",
        "model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{model_version}\")\n",
        "\n",
        "# Prepare a new data point for prediction (replace with actual data)\n",
        "new_data = pd.DataFrame({\n",
        "    \"length\": [1.080547],\n",
        "    \"weight\": [-1.245423],\n",
        "    \"neighbors\": [2.209168],\n",
        "    \"income\": [1.838642],\n",
        "    \"looped\": [1.763154],\n",
        "    \"count\": [0.223435]\n",
        "})\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(new_data)\n",
        "print(\"Predictions:\", predictions)"
      ],
      "metadata": {
        "id": "IQz-tv5YZdjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow.pyfunc\n",
        "\n",
        "# Load the model using the registered model name and version\n",
        "model_name = \"xgboost_m1\"\n",
        "model_version = 1  # Specify the version of the model you want to use\n",
        "model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{model_version}\")\n",
        "\n",
        "# Prepare a new data point for prediction (replace with actual data)\n",
        "new_data = pd.DataFrame({\n",
        "    \"length\": [1.080547],\n",
        "    \"weight\": [-1.245423],\n",
        "    \"neighbors\": [2.209168],\n",
        "    \"income\": [1.838642],\n",
        "    \"looped\": [1.763154],\n",
        "    \"count\": [0.223435]\n",
        "})\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(new_data)\n",
        "print(\"Predictions:\", predictions[0][0])"
      ],
      "metadata": {
        "id": "v3WqSAD2ZxHp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}